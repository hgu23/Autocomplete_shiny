{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import collections\n",
    "import pickle\n",
    "import autocomplete2\n",
    "from collections import Counter\n",
    "from bottle import route, run, debug\n",
    "from autocomplete2 import predict\n",
    "from autocomplete2 import models\n",
    "from autocomplete2 import helpers\n",
    "from autocomplete2 import split_predict\n",
    "from autocomplete2 import predict_currword\n",
    "from autocomplete2 import predict_second_word_given_first\n",
    "from autocomplete2 import predict_currword_given_lastword\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Loading the medicinal products MIMIC-III database ###\n",
    "procedures = open(\"procedures_100k.txt\").read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9102582\n"
     ]
    }
   ],
   "source": [
    "print(len(body_struct))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"\n"
     ]
    }
   ],
   "source": [
    "print(procedures[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "splitted = procedures.split(']\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100001\n"
     ]
    }
   ],
   "source": [
    "print(len(splitted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\"['ct', 'pelvis', 'with', 'intravenous', 'contrast', ':', 'a', 'heterogeneous', 'centrally'\n"
     ]
    }
   ],
   "source": [
    "print(splitted[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Removing unwanted characters from each query and appending it into a list ####\n",
    "string_list = []\n",
    "for i in range(0,len(splitted)):\n",
    "    string = splitted[i]\n",
    "    new = string.replace('\"[','')\n",
    "    new2 = new.replace(\"'\",'')\n",
    "    string_list.append(new2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "sustained, release, po, q12h, (, every, 12, hours, ), .\n"
     ]
    }
   ],
   "source": [
    "print(string_list[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Further splitting each query list using , as the split character ####\n",
    "word_list = []\n",
    "for i in range(0,len(string_list)):\n",
    "    string = string_list[i]\n",
    "    new = string.split(\", \")\n",
    "    word_list.append(new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['\\nsustained', 'release', 'po', 'q12h', '(', 'every', '12', 'hours', ')', '.']\n"
     ]
    }
   ],
   "source": [
    "print(word_list[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Converting each query from a list of strings to a sentence ####\n",
    "query_list = []\n",
    "for k in range(0,len(word_list)):\n",
    "    curr_word_list = word_list[k]\n",
    "    query = ' '.join(word for word in curr_word_list)\n",
    "    query_list.append(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "requiring cholecystostomy tube .\n"
     ]
    }
   ],
   "source": [
    "print(query_list[4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### Writing each sentence into a new text file ####\n",
    "with open('/Users/harshitg/github/autocomplete/autocomplete/procedures.txt','w') as f:\n",
    "    for item in query_list:\n",
    "        f.write(\"%s\" % item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "txt = open(\"procedures.txt\").read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving to: /Users/harshitg/github/autocomplete/autocomplete/models_compressed.pkl\n",
      "saving to: /Users/harshitg/github/autocomplete/autocomplete/models_compressed.pkl\n",
      "saving to: /Users/harshitg/github/autocomplete/autocomplete/models_compressed.pkl\n",
      "saving to: /Users/harshitg/github/autocomplete/autocomplete/models_compressed.pkl\n",
      "saving to: /Users/harshitg/github/autocomplete/autocomplete/models_compressed.pkl\n",
      "saving to: /Users/harshitg/github/autocomplete/autocomplete/models_compressed.pkl\n",
      "saving to: /Users/harshitg/github/autocomplete/autocomplete/models_compressed.pkl\n",
      "saving to: /Users/harshitg/github/autocomplete/autocomplete/models_compressed.pkl\n",
      "saving to: /Users/harshitg/github/autocomplete/autocomplete/models_compressed.pkl\n",
      "saving to: /Users/harshitg/github/autocomplete/autocomplete/models_compressed.pkl\n",
      "[2.8596978187561035, 2.7933528423309326, 2.688275098800659, 2.703906774520874, 2.7640082836151123, 2.780555009841919, 2.754356861114502, 2.8070850372314453, 2.7858996391296387, 2.8301258087158203]\n"
     ]
    }
   ],
   "source": [
    "##### Training python's autocomplete on the pre-processed .txt file #####\n",
    "k = 0\n",
    "elapsed_list = []\n",
    "while k<10:\n",
    "    start = time.time()\n",
    "    models.train_models(txt,model_name=\"models_compressed.pkl\")\n",
    "    end = time.time()\n",
    "    elapsed_time = end - start \n",
    "    elapsed_list.append(elapsed_time)\n",
    "    k += 1\n",
    "print(elapsed_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('ultrasound', 199),\n",
       " ('hysterectomy', 60),\n",
       " ('aortic', 59),\n",
       " ('incision', 39),\n",
       " ('x', 37),\n",
       " ('pain', 33),\n",
       " ('wall', 26),\n",
       " ('closure', 19),\n",
       " ('imaging', 18),\n",
       " ('aortogram', 16),\n",
       " ('colectomy', 14),\n",
       " ('computerized', 13),\n",
       " ('ct', 12),\n",
       " ('wound', 11),\n",
       " ('radiograph', 9)]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##### Predicting the second word given only the first word #####\n",
    "predict_second_word_given_first(\"abdominal\",top_n = 15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The number following each autocomplete suggestion is the frequency of each word."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('hr', 4206),\n",
       " ('had', 3666),\n",
       " ('his', 3265),\n",
       " ('he', 3012),\n",
       " ('her', 2418),\n",
       " ('hospital', 2152),\n",
       " ('hemodialysis', 1024),\n",
       " ('have', 913),\n",
       " ('hematocrit', 912),\n",
       " ('head', 818)]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "###### Predicting only the current word #####\n",
    "predict_currword(\"h\",top_n = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['a']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('aortic', 59),\n",
       " ('aortogram', 16),\n",
       " ('and', 6),\n",
       " ('aortography', 6),\n",
       " ('aorta', 4)]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##### Predicting the second word given the first word and part of the second word ####\n",
    "predict_currword_given_lastword(\"abdominal\",\"a\",top_n = 5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
