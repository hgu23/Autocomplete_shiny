{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import collections\n",
    "import pickle\n",
    "import autocomplete2\n",
    "import re \n",
    "from collections import Counter\n",
    "from bottle import route, run, debug\n",
    "from autocomplete2 import predict\n",
    "from autocomplete2 import models\n",
    "from autocomplete2 import helpers\n",
    "from autocomplete2 import split_predict\n",
    "from autocomplete2 import predict_currword\n",
    "from autocomplete2 import predict_second_word_given_first\n",
    "from autocomplete2 import predict_currword_given_lastword\n",
    "from gensim.utils import simple_preprocess as pre_process\n",
    "from nltk.tokenize.treebank import TreebankWordDetokenizer\n",
    "from spacy.lang.en.stop_words import STOP_WORDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Combining all the mimic databases into one big .txt file #####\n",
    "filenames = ['body_struct.txt', 'disorders.txt','procedures.txt','medicinal_products.txt']\n",
    "with open('/Users/harshitg/github/autocomplete/autocomplete/combined_mimic.txt', 'w') as outfile:\n",
    "    for fname in filenames:\n",
    "        with open(fname) as infile:\n",
    "            for line in infile:\n",
    "                outfile.write(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Defining a function which removes Stop words from Spacy and splits each query into a list of strings####\n",
    "def tokenize(query):\n",
    "    return [token for token in query.split() if token not in STOP_WORDS]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Combining the diseases and genes HPO .txt files into one big .txt file ####\n",
    "filenames = ['genes_all_HPO.txt', 'diseases_all_HPO.txt']\n",
    "with open('/Users/harshitg/github/autocomplete/autocomplete/combined_hpo.txt', 'w') as outfile:\n",
    "    for fname in filenames:\n",
    "        query_list = open(fname).readlines()\n",
    "        for line in query_list:\n",
    "            outfile.write(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Loading the combined hpo file ####\n",
    "queries = open(\"combined_hpo.txt\").readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Removing the tabline characters from the combined hpo file ####\n",
    "output_file_name = '/Users/harshitg/github/autocomplete/autocomplete/combined_hpo_processed.txt'\n",
    "with open(output_file_name, 'w+') as out_file:\n",
    "    for i in range(0,len(queries)):\n",
    "        queries[i] = tokenize(queries[i])\n",
    "        queries[i] = TreebankWordDetokenizer().detokenize(queries[i])\n",
    "        out_file.write(queries[i]+ \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Combining all the medical text files into one big text file ####\n",
    "filenames = ['combined_mimic.txt', 'ICD10_2.txt','combined_hpo_processed.txt']\n",
    "with open('/Users/harshitg/github/autocomplete/autocomplete/everything_combined.txt', 'w') as outfile:\n",
    "    for fname in filenames:\n",
    "        with open(fname) as infile:\n",
    "            for line in infile:\n",
    "                outfile.write(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Loading the combined text file as a list of queries ####\n",
    "queries = open(\"everything_combined.txt\").readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ct pelvis intravenous contrast: heterogeneous centrally'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "queries[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Removing stop words from the combined text file ####\n",
    "output_file_name = '/Users/harshitg/github/autocomplete/autocomplete/everything_combined_processed.txt'\n",
    "with open(output_file_name, 'w+') as out_file:\n",
    "    for i in range(0,len(queries)):\n",
    "        queries[i] = TreebankWordDetokenizer().det\n",
    "        queries[i] = tokenize(queries[i])okenize(queries[i])\n",
    "        out_file.write(queries[i]+ \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_list = open(\"everything_combined_processed.txt\").readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Removing specific chosen special characters from the processed text file ####\n",
    "query_list2 = []\n",
    "for query in query_list:\n",
    "    query = re.sub('[#*;]', '', query)\n",
    "    query_list2.append(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Loading the unprocessed combined text file as a list of queries ####\n",
    "query_list = open(\"everything_combined.txt\").readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Removing a wider range of special characters from the unprocessed text file for single word autocompletion ####\n",
    "query_list2 = []\n",
    "for query in query_list:\n",
    "    query = re.sub('[\\(\\[,#*;\\)\\]]', '', query)\n",
    "    query_list2.append(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### Writing each query to a new .txt file to be used for single word autocompletion ####\n",
    "with open('/Users/harshitg/github/autocomplete/autocomplete/everything_combined_single.txt', 'w') as outfile:\n",
    "    for query in query_list2:\n",
    "        outfile.write(query)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
